{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: Wang Hong Wen 王泓文\n",
    "\n",
    "Student ID: 107071006\n",
    "\n",
    "GitHub ID: bluebird1337\n",
    "\n",
    "Kaggle name:演繹者\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "\n",
    "![pic0](pic0.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2021-Lab2-master Repo](https://github.com/fhcalderon87/DM2021-Lab2-master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/c/dm2021-lab2-hw2/) regarding Emotion Recognition on Twitter. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Dec. 24th 11:59 pm, Friday)__. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Dec. 29th 11:59 pm, Wednesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the **DM2021_Lab2_homeword_solve** file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Report of developping the model for the competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cause I don't have server and GPU, I can't use large language model to do this homework\n",
    "\n",
    "(google colab has RAM limit, I tried but crushed for so many time...\n",
    "\n",
    "in the end, I use the simplest way of **tf-idf** + some basic feature of a text\n",
    "\n",
    "and only process about 30000 tweets\n",
    "\n",
    "then use skilearn to get the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic features: \n",
    "\n",
    "1. Character Length: `dat['character_len'] = dat['tweets'].str.len()`\n",
    "\n",
    "2. Word Count: `dat['word_counts'] = dat['tweets'].str.split().str.len()`\n",
    "\n",
    "3. Average Character Length per Word: `dat['characters_per_word'] = dat['character_cnt']/dat['word_counts']`\n",
    "\n",
    "4. Special Character Count: `dat['spl'] = dat['Tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('@')]))`\n",
    "\n",
    "5. Number Count: `dat['num'] = dat['Tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the Raw Text\n",
    "\n",
    "1. Removing punctuation:  `dat['processedtext'] = dat['Tweet'].str.replace('[^\\w\\s]','') `\n",
    "2. Removing stopwords: `dat['processedtext'] = dat['processedtext'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))`\n",
    "3. Conversion to lowercase : `dat['processedtext'] = dat['processedtext'].apply(lambda x: \" \".join(x.lower() for x in x.split()))`\n",
    "4. Stemming: `dat['processedtext'] = dat['processedtext'].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF feature\n",
    "`tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='utf-8', ngram_range=(1, 2))`\n",
    "\n",
    "`features = tfidf.fit_transform(dat.processedtext).toarray()`\n",
    "\n",
    "ngram_range is set to (1, 2) to indicate that I want to consider both unigrams and bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine these feature, also use concept of active learning query committee\n",
    "\n",
    "https://modal-python.readthedocs.io/en/latest/content/examples/query_by_committee.html\n",
    "\n",
    "`committee = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use all these model in skilearn and choose the prediction that one of the model have the highest `predict_proba` as my final predicion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight\n",
    "observe the `cross validation score of each model give different weight based on their score\n",
    "\n",
    "`\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in the data explore process I found that the train data have a huge imballanced class issues, \n",
    "\n",
    "![alt text](imbalance.png \"Title\")\n",
    "\n",
    "Since I the model I mention above can't fit with size=1M data, so I use sample about only 10000 sentence to create feature, which worsen the imballance issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that's all about the sad result on leaderboad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
